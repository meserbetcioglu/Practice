{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Get the wiki page for Marvel Cinematic Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_address = \"https://en.wikipedia.org\"\n",
    "marvel_address = wiki_address + \"/wiki/List_of_Marvel_Cinematic_Universe_films\"\n",
    "r = requests.get(marvel_address)\n",
    "\n",
    "# Convert to beautiful soup object\n",
    "soup = bs(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Select relevant data from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tables from the page\n",
    "movie_table = soup.find_all(class_=\"wikitable plainrowheaders\")[:2]\n",
    "movie_rows = []\n",
    "for index, table in enumerate(movie_table):\n",
    "    if index == 0:\n",
    "        movie_rows.append(table.find_all(\"tr\"))    \n",
    "    movie_rows.append(table.find_all(\"tr\")[1:])\n",
    "\n",
    "def get_subsect(main_row):\n",
    "    sub_rows = main_row.find_all(\"li\")\n",
    "    subsect_list = []\n",
    "    for row in sub_rows:\n",
    "        row_text = row.find(class_=\"toctext\").get_text()\n",
    "        if row.find(\"ul\"):\n",
    "            subsect_list.append(row_text + \":\")\n",
    "            subsect_list.append(get_subsect(row))\n",
    "        else:\n",
    "            subsect_list.append(row_text)\n",
    "    return subsect_list\n",
    "\n",
    "def get_linked_content(address):\n",
    "    r_c = requests.get(address)\n",
    "    soup_c = bs(r_c.content)\n",
    "    \n",
    "    toc = soup_c.find(class_=\"toc\").find(\"ul\")\n",
    "    toc_rows = toc.find_all(\"li\")\n",
    "\n",
    "    content_list = []\n",
    "    for row in toc_rows:\n",
    "        row_text = row.find(class_=\"toctext\").get_text()\n",
    "        if row_text == 'See also':\n",
    "            break\n",
    "        if row.find(\"ul\"):\n",
    "            content_list.append(row_text + \":\")\n",
    "            content_list.append(get_subsect(row))\n",
    "            continue\n",
    "\n",
    "        content_list.append(row_text)\n",
    "\n",
    "    return content_list\n",
    "\n",
    "def get_box_info(row):\n",
    "    row_text = row.find(\"td\").get_text()\n",
    "    if \"Full list\" in row_text:\n",
    "        content_address = wiki_address + row.find(href = True)['href']\n",
    "        return get_linked_content(content_address)\n",
    "    elif row.find(\"li\"):\n",
    "        return [li.get_text() for li in row.find_all(\"li\")]\n",
    "    else:\n",
    "        return row_text\n",
    "\n",
    "def get_movie_page_info(link):\n",
    "    r_c = requests.get(wiki_address + link)\n",
    "    soup_c = bs(r_c.content)\n",
    "    info_box = soup.find(class_=\"infobox vevent\")\n",
    "    info_rows = info_box.find_all(\"tr\")\n",
    "\n",
    "    movie_info = {}\n",
    "\n",
    "    for i, row in enumerate(info_rows):\n",
    "        if i == 0:\n",
    "            movie_info[\"Title\"] = row.find(\"th\").get_text()\n",
    "        elif i == 1:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                movie_key = row.find(\"th\").get_text()\n",
    "                movie_value = get_box_info(row)\n",
    "                movie_info[movie_key] = movie_value\n",
    "            except:\n",
    "                continue\n",
    "    return movie_info\n",
    "\n",
    "# Collect table rows and row links\n",
    "table_rows = []\n",
    "box_rows = []\n",
    "for table in movie_rows:\n",
    "    for row in table:\n",
    "        try:\n",
    "            if(row.find(\"th\")['scope'] == \"row\") and row not in table_rows:\n",
    "                table_rows.append(row)\n",
    "\n",
    "                # Data from individual movie pages are collected to be merged later.\n",
    "                link = row.find(href = True)['href']\n",
    "                box_row = get_movie_page_info(link)\n",
    "                box_rows.append(box_row)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context units are collected from the header of the table.\n",
    "key_list = []\n",
    "for col in movie_rows[0][0].find_all(\"th\"):\n",
    "    key_list.append(col.get_text().replace(\"\\n\", \"\"))\n",
    "\n",
    "# Data is collected from columns and paired with context units \n",
    "# in a movie class, which is then stored in a list.\n",
    "movie_list = []\n",
    "for i, row in enumerate(table_rows):\n",
    "    value_list = []\n",
    "    for col in row.find_all(\"th\") + row.find_all(\"td\"):\n",
    "        col_text = col.get_text()\n",
    "\n",
    "        # Clean the data\n",
    "        if \"[\" in col_text:\n",
    "            col_text = col_text.split(\"[\")[0] + \"\\n\"\n",
    "            \n",
    "        value_list.append(col_text.replace(\"\\n\", \"\"))\n",
    "    movie_list.append({**dict(zip(key_list, value_list)), **box_rows[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Cleanup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Film': 'Iron Man',\n",
       " 'U.S. release date': 'May 2, 2008',\n",
       " 'Director(s)': 'Jon Favreau',\n",
       " 'Screenwriter(s)': 'Mark Fergus & Hawk Ostby and Art Marcum & Matt Holloway',\n",
       " 'Producer(s)': 'Avi Arad and Kevin Feige',\n",
       " 'Title': 'Marvel Cinematic Universe films',\n",
       " 'Based on': 'Characters publishedby Marvel Comics',\n",
       " 'Produced by': ['Kevin Feige[a]', 'Gale Anne Hurd (TIH)', 'Amy Pascal (SM)'],\n",
       " 'Starring': 'See below',\n",
       " 'Productioncompanies': ['Marvel Studios',\n",
       "  'Columbia Pictures(SM; 2017–present)'],\n",
       " 'Distributed by': ['Paramount Pictures(2008–2011)',\n",
       "  'Universal Pictures(TIH; 2008)',\n",
       "  'Walt Disney StudiosMotion Pictures(2012–present)',\n",
       "  'Sony Pictures Releasing (SM; 2017–present)'],\n",
       " 'Release date': '2008–present',\n",
       " 'Country': 'United States',\n",
       " 'Language': 'English',\n",
       " 'Budget': 'Total (27 films):$5.100,5–5.558\\xa0billion',\n",
       " 'Box office': 'Total (27 films):$25.694\\xa0billion'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Print and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "def print_dict(dict):\n",
    "        print(\"\\n\")\n",
    "        for key in dict:\n",
    "            print(key + \": \" + dict[key] + \"\\n\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# for movie in movie_list:\n",
    "#     print_dict(movie)\n",
    "\n",
    "# Function to save the list as text file\n",
    "def save_txt(filename, list):\n",
    "    with open(filename + \".txt\", 'w') as f: \n",
    "        for dict in list:\n",
    "            f.write('\\n')\n",
    "            for key in dict: \n",
    "                f.write('%s: %s' % (key, dict[key]))\n",
    "\n",
    "# Function to save the list as csv file\n",
    "def save_csv(filename, data_list):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    df.to_csv(filename + \".csv\")\n",
    "\n",
    "# Function to save the list as excel file\n",
    "def save_xlsx(filename, data_list):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    writer = pd.ExcelWriter(filename + \".xlsx\", engine='xlsxwriter')\n",
    "    df.to_excel(writer,sheet_name = filename, index=False)\n",
    "    writer.save() \n",
    "\n",
    "# Save the results\n",
    "save_txt(\"MCU\", movie_list)\n",
    "save_csv(\"MCU\", movie_list)\n",
    "save_xlsx(\"MCU\", movie_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6ee3df190db0cf4ce9d66d444f586cbb95e12f7ba56dc797574d97011af8020"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
